---
title: "Students Writing Their Own Exam Questions"
date: 2019-09-11T11:22:55-05:00
categories: [teaching, pedagogy]
footnotes: false
htmlwidgets: false
mathjax: false
draft: true
---
Writing good exam questions is hard. If done correctly, the student should have no idea the lengths you went through to write a good set of questions. But maybe they should know just how difficult it really is. This semester I tried an experiment: allow my masters students a chance to write their own midterm exam (with some pretty specific guidelines). We'll see how it turns out, but so far I have been impressed with how much they have taken to the idea.

<!--more-->

### The guidelines
After some course specific introductory text, I outline the three main parts of the task.

> 1. **The intended learning outcome of the question**. What is it that you want a student to demonstrate knowledge of? The learning objectives of this course are a good starting place.
> 2. **The problem situation**. What is the context of the question? This helps studentâ€™s ground their understanding of the question in the real world and better link it to the theoretical material in the course.
> 3. **The essay question**. This essentially combines the previous two points. What aspects of the problem situation do you want the student to probe to demonstrate the learning outcome? This should take the form of application or integration (see the syllabus for definitions of these).

You can see the syllabus I am referring to on my [PSPA 611 page](/teaching/2019f-revenue/).

The inspiration for these tasks comes from [a handbook on preparing effective essay questions](https://testing.byu.edu/handbooks/WritingEffectiveEssayQuestions.pdf). I particularly like the first point about the learning objective. I'm not entirely sure students stop to take the time to think about what concepts an exam question is meant to probe beyond the immediate task in the question.

From here I diverge somewhat with [what others have done](https://www.facultyfocus.com/articles/educational-assessment/student-written-exams-increase-student-involvement/). I offered this as a small amount of extra credit to anyone who turned in a proposed question. From this pool, I chose 3 questions (and added a 4th of my own to round out the topics) to appear on the exam. The exams are out in the wild right now so I don't have a conclusion to this experiment just yet (consider this a pre-registration); however, if it goes as well as it appears to be going, I am plan to integrate this assignment into the midterm proper in future semesters.

### Take aways so far
Having thought about this quite a bit, I like the incentives baked into something like this. It gets the students to think about what they are learning in multiple ways that can be difficult to do otherwise. Specifying a learning objective allows them to be contemplative about the big topics in the course and then narrow them down to something more manageable. It also allows for application of these topics to a particular context; a context that the student is likely familiar with. In the [NIU MPA program](https://mpa.niu.edu), we are particularly concerned with translating in-class experiences to the workplace.[^1] This small task allows some more abstract concepts to be applied.

Overall, I am fairly happy with how this experiment has gone so far.

[^1]: For context, our program requires all students to either be working in the public/non-profit sector or engaged in an internship. This allows for almost immediate translation of course concepts to the workplace.
